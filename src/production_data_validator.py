"""
üõ°Ô∏è VALIDADOR DE DADOS PARA PRODU√á√ÉO
Sistema de Trading ML v2.0 - Anti-Dummy Data

CR√çTICO: Este m√≥dulo DEVE ser usado em TODOS os pontos de entrada de dados
antes de qualquer processamento ML ou gera√ß√£o de sinais de trading.
"""

import os
import logging
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
import warnings


class ProductionDataError(Exception):
    """Exce√ß√£o cr√≠tica para dados n√£o adequados para produ√ß√£o"""
    pass


class ProductionDataValidator:
    """
    Validador rigoroso para dados de produ√ß√£o
    
    OBJETIVO: Garantir que NENHUM dado sint√©tico, dummy ou mock
    seja usado em opera√ß√µes reais de trading.
    """
    
    def __init__(self):
        self.logger = logging.getLogger('ProductionValidator')
        self.production_mode = os.getenv('TRADING_PRODUCTION_MODE', 'False').lower() == 'true'
        self.strict_mode = os.getenv('STRICT_VALIDATION', 'True').lower() == 'true'
        
        if self.production_mode:
            self.logger.info("üõ°Ô∏è MODO PRODU√á√ÉO ATIVADO - VALIDA√á√ÉO RIGOROSA")
        else:
            self.logger.warning("‚ö†Ô∏è MODO DESENVOLVIMENTO - DADOS PODEM SER SINT√âTICOS")
    
    def validate_trading_data(self, 
                            data: pd.DataFrame, 
                            source: str,
                            data_type: str = 'market') -> bool:
        """
        Valida√ß√£o principal para dados de trading
        
        Args:
            data: DataFrame com dados de mercado
            source: Fonte dos dados ('ProfitDLL', 'WebSocket', 'API', etc.)
            data_type: Tipo de dados ('market', 'historical', 'realtime')
            
        Returns:
            bool: True se dados s√£o seguros para produ√ß√£o
            
        Raises:
            ProductionDataError: Se dados dummy/unsafe detectados
        """
        
        if data.empty:
            raise ProductionDataError(f"DataFrame vazio recebido de {source}")
        
        # üîç BATERIA DE TESTES ANTI-DUMMY
        validation_results = {
            'synthetic_patterns': self._detect_synthetic_patterns(data),
            'timestamp_integrity': self._validate_timestamps(data, data_type),
            'price_integrity': self._validate_price_integrity(data),
            'volume_patterns': self._validate_volume_patterns(data),
            'data_source': self._validate_data_source(source),
            'nan_patterns': self._validate_nan_patterns(data)
        }
        
        # üö® ANALISAR RESULTADOS
        failed_validations = []
        for test_name, result in validation_results.items():
            if result['failed']:
                failed_validations.append(f"{test_name}: {result['reason']}")
        
        if failed_validations:
            error_msg = (
                f"üö® DADOS SUSPEITOS DETECTADOS EM {source.upper()}\n"
                f"Tipo: {data_type}\n"
                f"Falhas: {'; '.join(failed_validations)}\n"
                f"‚õî TRADING BLOQUEADO POR SEGURAN√áA"
            )
            
            if self.production_mode:
                raise ProductionDataError(error_msg)
            else:
                self.logger.warning(error_msg)
                return False
        
        self.logger.info(f"‚úÖ Dados validados: {source} - {data_type} - {len(data)} registros")
        return True
    
    def _detect_synthetic_patterns(self, data: pd.DataFrame) -> Dict[str, Any]:
        """Detecta padr√µes t√≠picos de dados sint√©ticos"""
        
        try:
            # ‚ùå TESTE 1: Volume muito uniforme (padr√£o np.random.uniform)
            if 'volume' in data.columns:
                volume_cv = data['volume'].std() / data['volume'].mean()
                if volume_cv < 0.15:  # Coeficiente de varia√ß√£o muito baixo
                    return {
                        'failed': True, 
                        'reason': f'Volume uniforme demais (CV={volume_cv:.3f})'
                    }
            
            # ‚ùå TESTE 2: Spreads muito constantes (padr√£o sint√©tico)
            if all(col in data.columns for col in ['high', 'low', 'close']):
                spreads = (data['high'] - data['low']) / data['close']
                
                # Verificar se h√° spreads v√°lidos
                valid_spreads = spreads[spreads > 0]
                if len(valid_spreads) == 0:
                    # Se todos os spreads s√£o zero, pode ser leg√≠timo para dados de minuto
                    return {'failed': False, 'reason': 'Spreads zero aceit√°veis para dados de alta frequ√™ncia'}
                
                spread_cv = valid_spreads.std() / valid_spreads.mean()
                
                # Threshold muito mais relaxado para dados reais de alta frequ√™ncia
                threshold = 0.001 if self.production_mode else 0.00001
                
                if spread_cv < threshold:
                    # Em desenvolvimento, apenas avisar
                    if not self.production_mode:
                        self.logger.warning(f"Spreads uniformes detectados (CV={spread_cv:.6f}) - aceit√°vel em desenvolvimento")
                        return {'failed': False, 'reason': 'OK'}
                    else:
                        return {
                            'failed': True,
                            'reason': f'Spreads uniformes demais (CV={spread_cv:.6f})'
                        }
            
            # ‚ùå TESTE 3: Detectar sequ√™ncias suspeitas
            if 'price' in data.columns:
                price_diffs = data['price'].diff()
                # Muito poucos valores √∫nicos = poss√≠vel simula√ß√£o
                unique_ratio = price_diffs.nunique() / len(price_diffs)
                if unique_ratio < 0.7:
                    return {
                        'failed': True,
                        'reason': f'Mudan√ßas de pre√ßo pouco variadas ({unique_ratio:.2f})'
                    }
            
            # ‚ùå TESTE 4: Detectar padr√µes de np.random.seed
            if 'volume' in data.columns and len(data) > 10:
                # Teste de aleatoriedade usando runs test
                median_vol = data['volume'].median()
                runs = self._count_runs_above_below_median(data['volume'], median_vol)
                expected_runs = len(data) / 2
                if abs(runs - expected_runs) / expected_runs > 0.3:
                    return {
                        'failed': True,
                        'reason': 'Padr√£o de volume n√£o-aleat√≥rio detectado'
                    }
            
            return {'failed': False, 'reason': 'OK'}
            
        except Exception as e:
            return {'failed': True, 'reason': f'Erro na detec√ß√£o sint√©tica: {str(e)}'}
    
    def _validate_timestamps(self, data: pd.DataFrame, data_type: str) -> Dict[str, Any]:
        """Valida integridade dos timestamps"""
        
        try:
            # Verificar se h√° coluna de timestamp ou index datetime
            timestamp_col = None
            if hasattr(data.index, 'dtype') and 'datetime' in str(data.index.dtype):
                timestamps = data.index
            elif 'timestamp' in data.columns:
                timestamps = pd.to_datetime(data['timestamp'])
            elif 'datetime' in data.columns:
                timestamps = pd.to_datetime(data['datetime'])
            else:
                return {'failed': True, 'reason': 'Nenhuma coluna de timestamp encontrada'}
            
            # ‚ùå TESTE 1: Timestamps muito antigos para tempo real
            if data_type == 'realtime':
                latest_time = timestamps.max()
                if pd.isna(latest_time):
                    return {'failed': True, 'reason': 'Timestamp inv√°lido (NaT)'}
                
                # Remover timezone para compara√ß√£o
                if hasattr(latest_time, 'tz') and latest_time.tz is not None:
                    latest_time = latest_time.replace(tzinfo=None)
                
                time_diff = datetime.now() - latest_time
                if time_diff > timedelta(minutes=10):
                    return {
                        'failed': True,
                        'reason': f'Dados muito antigos ({time_diff}) para tempo real'
                    }
            
            # ‚ùå TESTE 2: Intervalos muito regulares (suspeito)
            if len(timestamps) > 5:
                try:
                    # Converter para Series para usar diff de forma segura
                    ts_series = pd.Series(pd.to_datetime(timestamps))
                    intervals = ts_series.diff().dropna()
                        
                    if len(intervals) > 0:
                        # Todos os intervalos iguais = poss√≠vel simula√ß√£o
                        unique_intervals = intervals.nunique()
                        if unique_intervals == 1 and len(intervals) > 10:
                            return {
                                'failed': True,
                                'reason': 'Intervalos de tempo perfeitamente regulares (suspeito)'
                            }
                except Exception:
                    # Se n√£o conseguir calcular intervalos, pular teste
                    pass
            
            # ‚ùå TESTE 3: Timestamps duplicados
            if timestamps.duplicated().any():
                return {'failed': True, 'reason': 'Timestamps duplicados detectados'}
            
            return {'failed': False, 'reason': 'OK'}
            
        except Exception as e:
            return {'failed': True, 'reason': f'Erro na valida√ß√£o de timestamp: {str(e)}'}
    
    def _validate_price_integrity(self, data: pd.DataFrame) -> Dict[str, Any]:
        """Valida integridade dos dados de pre√ßo"""
        
        try:
            price_cols = []
            for col in ['price', 'close', 'open', 'high', 'low']:
                if col in data.columns:
                    price_cols.append(col)
            
            if not price_cols:
                return {'failed': False, 'reason': 'Nenhuma coluna de pre√ßo para validar'}
            
            for col in price_cols:
                prices = data[col]
                
                # ‚ùå TESTE 1: Pre√ßos zeros ou negativos
                if (prices <= 0).any():
                    return {
                        'failed': True,
                        'reason': f'Pre√ßos inv√°lidos (‚â§0) encontrados em {col}'
                    }
                
                # ‚ùå TESTE 2: Mudan√ßas imposs√≠veis (>50% em poucos registros)
                if len(prices) > 1:
                    price_changes = prices.pct_change().abs()
                    extreme_changes = (price_changes > 0.5).sum()
                    if extreme_changes > len(prices) * 0.05:  # Mais de 5% mudan√ßas extremas
                        return {
                            'failed': True,
                            'reason': f'Mudan√ßas de pre√ßo extremas em {col} ({extreme_changes} casos)'
                        }
                
                # ‚ùå TESTE 3: Pre√ßos muito constantes
                if prices.nunique() < len(prices) * 0.8 and len(prices) > 10:
                    return {
                        'failed': True,
                        'reason': f'Pre√ßos pouco variados em {col} (poss√≠vel simula√ß√£o)'
                    }
            
            # ‚ùå TESTE 4: Validar OHLC se dispon√≠vel
            if all(col in data.columns for col in ['open', 'high', 'low', 'close']):
                # High deve ser >= max(open, close)
                invalid_high = (data['high'] < data[['open', 'close']].max(axis=1)).any()
                # Low deve ser <= min(open, close)  
                invalid_low = (data['low'] > data[['open', 'close']].min(axis=1)).any()
                
                if invalid_high or invalid_low:
                    return {
                        'failed': True,
                        'reason': 'Inconsist√™ncia em dados OHLC (high/low inv√°lidos)'
                    }
            
            return {'failed': False, 'reason': 'OK'}
            
        except Exception as e:
            return {'failed': True, 'reason': f'Erro na valida√ß√£o de pre√ßos: {str(e)}'}
    
    def _validate_volume_patterns(self, data: pd.DataFrame) -> Dict[str, Any]:
        """Valida padr√µes de volume"""
        
        try:
            volume_cols = [col for col in data.columns if 'volume' in col.lower()]
            
            if not volume_cols:
                return {'failed': False, 'reason': 'Nenhuma coluna de volume para validar'}
            
            for vol_col in volume_cols:
                volume = data[vol_col]
                
                # ‚ùå TESTE 1: Volume negativo
                if (volume < 0).any():
                    return {
                        'failed': True,
                        'reason': f'Volume negativo encontrado em {vol_col}'
                    }
                
                # ‚ùå TESTE 2: Muitos zeros (suspeito para dados reais)
                # EXCE√á√ÉO: buy_volume e sell_volume podem ter muitos zeros legitimamente
                if vol_col not in ['buy_volume', 'sell_volume']:
                    zero_pct = (volume == 0).sum() / len(volume)
                    if zero_pct > 0.3:  # Mais de 30% zeros
                        return {
                            'failed': True,
                            'reason': f'Muitos zeros em {vol_col} ({zero_pct:.1%}) - suspeito'
                        }
                else:
                    # Para buy/sell volume, s√≥ falhar se TODOS forem zero
                    if (volume == 0).all():
                        # Se √© desenvolvimento, apenas avisar
                        if self.production_mode:
                            return {
                                'failed': True,
                                'reason': f'Todos os valores de {vol_col} s√£o zero'
                            }
                        else:
                            self.logger.warning(f"{vol_col} com todos zeros - aceit√°vel em desenvolvimento")
                
                # ‚ùå TESTE 3: Volume muito uniforme
                if len(volume) > 10:
                    vol_cv = volume.std() / volume.mean()
                    if vol_cv < 0.2:  # Coeficiente de varia√ß√£o muito baixo
                        return {
                            'failed': True,
                            'reason': f'Volume uniforme demais em {vol_col} (CV={vol_cv:.3f})'
                        }
            
            return {'failed': False, 'reason': 'OK'}
            
        except Exception as e:
            return {'failed': True, 'reason': f'Erro na valida√ß√£o de volume: {str(e)}'}
    
    def _validate_data_source(self, source: str) -> Dict[str, Any]:
        """Valida se a fonte de dados √© confi√°vel para produ√ß√£o"""
        
        # Lista de fontes aprovadas para produ√ß√£o
        approved_sources = {
            'ProfitDLL',
            'MetaTrader5',  
            'B3API',
            'WebSocketReal',
            'BrokerAPI',
            'MarketDataFeed'
        }
        
        # Lista de fontes proibidas em produ√ß√£o
        forbidden_sources = {
            'mock', 'fake', 'dummy', 'test', 'simulation', 
            'synthetic', 'random', 'generator'
        }
        
        source_lower = source.lower()
        
        # ‚ùå Verificar fontes proibidas
        for forbidden in forbidden_sources:
            if forbidden in source_lower:
                return {
                    'failed': True,
                    'reason': f'Fonte proibida detectada: {source} (cont√©m "{forbidden}")'
                }
        
        # ‚ö†Ô∏è Verificar se √© fonte aprovada (apenas aviso)
        if self.production_mode and source not in approved_sources:
            self.logger.warning(f"Fonte n√£o reconhecida: {source}")
        
        return {'failed': False, 'reason': 'OK'}
    
    def _validate_nan_patterns(self, data: pd.DataFrame) -> Dict[str, Any]:
        """Valida padr√µes de NaN que podem indicar fillna perigoso"""
        
        try:
            # ‚ùå TESTE 1: Muitos NaN podem indicar dados incompletos
            total_cells = data.size
            nan_count = data.isnull().sum().sum()
            nan_ratio = nan_count / total_cells
            
            if nan_ratio > 0.1:  # Mais de 10% NaN
                return {
                    'failed': True,
                    'reason': f'Muitos valores NaN ({nan_ratio:.1%}) - dados incompletos'
                }
            
            # ‚ùå TESTE 2: Colunas com padr√µes suspeitos de fillna
            for col in data.columns:
                if data[col].dtype in ['float64', 'int64']:
                    # Verificar se h√° muitos zeros (poss√≠vel fillna(0))
                    zero_ratio = (data[col] == 0).sum() / len(data)
                    if zero_ratio > 0.5:  # Mais de 50% zeros
                        return {
                            'failed': True,
                            'reason': f'Coluna {col} com muitos zeros ({zero_ratio:.1%}) - poss√≠vel fillna(0)'
                        }
            
            return {'failed': False, 'reason': 'OK'}
            
        except Exception as e:
            return {'failed': True, 'reason': f'Erro na valida√ß√£o NaN: {str(e)}'}
    
    def _count_runs_above_below_median(self, series: pd.Series, median: float) -> int:
        """Conta runs acima/abaixo da mediana para teste de aleatoriedade"""
        
        above_median = series > median
        runs = 1
        
        for i in range(1, len(above_median)):
            if above_median.iloc[i] != above_median.iloc[i-1]:
                runs += 1
                
        return runs
    
    def validate_feature_data(self, features: pd.DataFrame) -> bool:
        """
        Valida√ß√£o espec√≠fica para dados de features ML
        
        Args:
            features: DataFrame com features calculadas
            
        Returns:
            bool: True se features s√£o seguras
        """
        
        if features.empty:
            raise ProductionDataError("DataFrame de features vazio")
        
        # ‚ùå Detectar features com fillna suspeito
        suspicious_cols = []
        
        for col in features.columns:
            if features[col].dtype in ['float64', 'int64']:
                # RSI com valor fixo 50 (suspeito)
                if 'rsi' in col.lower():
                    rsi_50_ratio = (features[col] == 50).sum() / len(features)
                    if rsi_50_ratio > 0.3:
                        suspicious_cols.append(f"{col}: muitos valores 50 (fillna suspeito)")
                
                # Features com muitos zeros
                zero_ratio = (features[col] == 0).sum() / len(features)
                if zero_ratio > 0.4:
                    suspicious_cols.append(f"{col}: muitos zeros ({zero_ratio:.1%})")
                
                # Features com valores constantes
                if features[col].nunique() < 3 and len(features) > 10:
                    suspicious_cols.append(f"{col}: valores pouco variados")
        
        if suspicious_cols:
            error_msg = f"Features suspeitas detectadas: {'; '.join(suspicious_cols)}"
            
            if self.production_mode:
                raise ProductionDataError(error_msg)
            else:
                self.logger.warning(error_msg)
                return False
        
        return True


def enforce_production_mode():
    """
    For√ßa modo produ√ß√£o baseado em vari√°vel de ambiente
    DEVE ser chamado no in√≠cio de qualquer sistema de trading
    """
    
    production_mode = os.getenv('TRADING_PRODUCTION_MODE', 'False').lower() == 'true'
    
    if production_mode:
        # Configura√ß√µes rigorosas para produ√ß√£o
        os.environ['STRICT_VALIDATION'] = 'True'
        warnings.filterwarnings('error')  # Warnings viram erros
        
        # Log de inicializa√ß√£o
        logger = logging.getLogger('ProductionMode')
        logger.critical("üõ°Ô∏è MODO PRODU√á√ÉO ATIVADO - VALIDA√á√ÉO RIGOROSA DE DADOS")
        logger.critical("‚ö†Ô∏è QUALQUER DADO SUSPEITO RESULTAR√Å EM BLOQUEIO DO SISTEMA")
        
        return True
    else:
        logger = logging.getLogger('DevelopmentMode')  
        logger.warning("‚ö†Ô∏è MODO DESENVOLVIMENTO - DADOS PODEM N√ÉO SER REAIS")
        return False


# Inst√¢ncia global do validador
production_validator = ProductionDataValidator()
