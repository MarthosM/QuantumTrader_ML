# ğŸ“– GUIA DO DESENVOLVEDOR - QuantumTrader_ML v2.0

## ğŸ¯ VisÃ£o Geral

O QuantumTrader_ML Ã© um sistema de trading algorÃ­tmico baseado em Machine Learning que integra anÃ¡lise de mercado em tempo real, detecÃ§Ã£o de regime e execuÃ§Ã£o automatizada atravÃ©s da ProfitDLL v4.0.

### Arquitetura Principal
- **Linguagem**: Python 3.8+
- **Framework ML**: TensorFlow/Keras, XGBoost, LightGBM
- **Dados**: ProfitDLL para market data real-time
- **Threading**: Processamento assÃ­ncrono multi-thread
- **PadrÃ£o**: Orientado a objetos com injeÃ§Ã£o de dependÃªncia

## ğŸ—ï¸ Classes Principais e MÃ©todos

### 1. TradingSystem (`trading_system.py`)
**Orquestrador principal do sistema**

```python
class TradingSystem:
    def __init__(self, config: Dict)
    def initialize(self) -> bool
    def start(self, ticker: Optional[str] = None) -> bool
    def stop(self)
    def _load_historical_data_safe(self, ticker: str, days_back: int) -> bool
    def _calculate_initial_features(self)
    def _start_processing_threads(self)
    def _main_loop(self)
    def _get_current_contract(self, date: datetime) -> str
```

**Responsabilidades:**
- Inicializar todos os componentes
- Gerenciar ciclo de vida do sistema
- Coordenar threads de processamento
- Validar dados de produÃ§Ã£o

**ConfiguraÃ§Ã£o MÃ­nima:**
```python
config = {
    'dll_path': './ProfitDLL64.dll',
    'username': 'user',
    'password': 'pass',
    'models_dir': './models/',
    'historical_days': 1,
    'ml_interval': 60,  # segundos
    'use_gui': True
}
```

### 2. ConnectionManagerV4 (`connection_manager_v4.py`)
**Interface com ProfitDLL**

```python
class ConnectionManagerV4:
    def __init__(self, dll_path: str)
    def initialize(self, key: str, username: str, password: str, ...) -> bool
    def connect(self) -> bool
    def disconnect(self)
    def subscribe_ticker(self, ticker: str) -> bool
    def request_historical_data(self, ticker: str, start_date: datetime, end_date: datetime) -> int
    def wait_for_historical_data(self, timeout_seconds: int = 30) -> bool
    def send_order(self, order: SendOrder) -> int
```

**Callbacks Importantes:**
- `on_trade_callback`: Processa trades em tempo real
- `on_agg_trade_callback`: Processa trades agregados
- `on_ticker_callback`: Atualiza preÃ§os bid/ask
- `on_order_book_callback`: Atualiza livro de ofertas
- `on_historical_data_callback`: Recebe dados histÃ³ricos

### 3. TradingDataStructure (`data_structure.py`)
**Estrutura centralizada de dados**

```python
class TradingDataStructure:
    # DataFrames principais
    candles: pd.DataFrame      # OHLCV
    microstructure: pd.DataFrame # Buy/sell volume, imbalance
    orderbook: pd.DataFrame     # Bid/ask, spread
    indicators: pd.DataFrame    # Technical indicators
    features: pd.DataFrame      # ML features
    
    def initialize_structure(self) -> None
    def update_candles(self, new_candles: pd.DataFrame) -> bool
    def update_microstructure(self, new_micro: pd.DataFrame) -> bool
    def update_indicators(self, new_indicators: pd.DataFrame) -> bool
    def update_features(self, new_features: pd.DataFrame) -> bool
    def check_data_quality(self) -> Dict[str, Any]
    def get_unified_dataframe(self) -> pd.DataFrame
```

**Estrutura de Dados:**
```python
# Candles (1 minuto)
{
    'open': float,
    'high': float, 
    'low': float,
    'close': float,
    'volume': float,
    'quantidade': int
}

# Microestrutura
{
    'buy_volume': float,
    'sell_volume': float,
    'buy_trades': int,
    'sell_trades': int,
    'volume_imbalance': float
}
```

### 4. FeatureEngine (`feature_engine.py`)
**Motor de cÃ¡lculo de features**

```python
class FeatureEngine:
    def __init__(self, required_features: List[str], allow_historical_data: bool = True)
    def calculate(self, data: TradingDataStructure) -> Dict[str, pd.DataFrame]
    def _calculate_technical_indicators(self, candles: pd.DataFrame) -> pd.DataFrame
    def _calculate_ml_features(self, data: TradingDataStructure) -> pd.DataFrame
    def _validate_features(self, features: pd.DataFrame) -> bool
    def get_feature_stats(self) -> Dict[str, Any]
```

**Features Calculadas:**
- **Indicadores TÃ©cnicos** (~45): EMAs, RSI, MACD, Bollinger Bands, ATR, Stochastic
- **Features ML** (~80-100): Momentum, volatilidade, retornos, volume ratios, regime strength

### 5. MLCoordinator (`ml_coordinator.py`)
**Coordenador do processo ML**

```python
class MLCoordinator:
    def __init__(self, model_manager, feature_engine, prediction_engine, regime_trainer)
    def process_prediction_request(self, data) -> Optional[Dict[str, Any]]
    def force_prediction(self, data) -> Optional[Dict[str, Any]]
    def _detect_market_regime(self, data) -> Optional[Dict[str, Any]]
    def _prepare_unified_data(self, data) -> pd.DataFrame
    def _analyze_support_resistance(self, data) -> Dict[str, Any]
    def _confirm_trend_direction(self, data) -> Dict[str, Any]
    def get_coordinator_stats(self) -> Dict[str, Any]
```

**Fluxo de PrediÃ§Ã£o:**
1. Detectar regime de mercado
2. Calcular features
3. Executar prediÃ§Ã£o baseada no regime
4. Validar se pode operar

### 6. RegimeAnalyzer (`training/regime_analyzer.py`)
**Detecta regime de mercado**

```python
class RegimeAnalyzer:
    def __init__(self, logger=None)
    def analyze_market(self, data: pd.DataFrame) -> Dict[str, Any]
    def _calculate_adx(self, data: pd.DataFrame, period: int = 14) -> pd.Series
    def _check_ema_alignment(self, data: pd.DataFrame) -> Tuple[bool, int]
    def _analyze_support_resistance(self, data: pd.DataFrame) -> Dict[str, float]
    def _calculate_regime_confidence(self, adx: float, regime: str) -> float
```

**Regimes Detectados:**
- `trend_up`: ADX > 25, EMAs alinhadas para cima
- `trend_down`: ADX > 25, EMAs alinhadas para baixo
- `range`: ADX < 25 (lateralizaÃ§Ã£o)
- `undefined`: ADX > 25 mas EMAs nÃ£o alinhadas

### 7. PredictionEngine (`prediction_engine.py`)
**Motor de prediÃ§Ãµes ML**

```python
class PredictionEngine:
    def __init__(self, model_manager, logger=None)
    def predict(self, features: pd.DataFrame) -> Optional[Dict[str, Any]]
    def predict_by_regime(self, features: pd.DataFrame, regime_info: Dict[str, Any]) -> Optional[Dict[str, Any]]
    def batch_predict(self, features_list: List[pd.DataFrame]) -> List[Dict[str, Any]]
    def _convert_model_result(self, model_result: Any) -> Dict[str, Any]
    def _convert_model_result_with_regime(self, model_result: Any, regime_info: Dict[str, Any]) -> Dict[str, Any]
```

**Formato de PrediÃ§Ã£o:**
```python
{
    'direction': float,      # -1 (sell) a 1 (buy)
    'magnitude': float,      # Movimento esperado
    'confidence': float,     # 0 a 1
    'regime': str,          # Regime detectado
    'timestamp': str,       # ISO format
    'model_used': str       # Modelo utilizado
}
```

### 8. SignalGenerator (`signal_generator.py`)
**Gera sinais de trading**

```python
class SignalGenerator:
    def __init__(self, config: Dict)
    def generate_signal(self, prediction: Dict, market_data) -> Dict
    def _validate_thresholds(self, direction: float, magnitude: float, confidence: float) -> Optional[Dict]
    def _calculate_levels(self, action: str, current_price: float, atr: float, magnitude: float, regime: str) -> Tuple[float, float]
    def _calculate_position_size(self, current_price: float, stop_loss: float, market_data) -> int
```

**Thresholds PadrÃ£o:**
```python
{
    'direction_threshold': 0.3,
    'magnitude_threshold': 0.0001,
    'confidence_threshold': 0.6,
    'min_stop_points': 5,
    'default_risk_reward': 2.0
}
```

### 9. RiskManager (`risk_manager.py`)
**Gerencia risco das operaÃ§Ãµes**

```python
class RiskManager:
    def __init__(self, config: Dict)
    def validate_signal(self, signal: Dict, account_balance: float, current_positions: Optional[List[Dict]] = None) -> Tuple[bool, str]
    def validate_signal_ml(self, signal: Dict, market_data: pd.DataFrame, portfolio_state: Dict, account_state: Dict) -> Dict
    def register_position(self, position: Dict)
    def close_position(self, position_id: str, exit_price: float, exit_reason: str) -> Dict
    def update_position_stop(self, position_id: str, new_stop: float) -> bool
    def get_risk_metrics(self) -> Dict
```

**ValidaÃ§Ãµes de Risco:**
1. Limite de posiÃ§Ãµes abertas
2. Perda diÃ¡ria mÃ¡xima
3. Risco por trade
4. Risk/reward mÃ­nimo
5. CorrelaÃ§Ã£o entre posiÃ§Ãµes
6. HorÃ¡rio de trading
7. Volatilidade do mercado

### 10. ModelManager (`model_manager.py`)
**Gerenciador de modelos ML**

```python
class ModelManager:
    def __init__(self, models_dir: str)
    def load_models(self) -> bool
    def predict(self, features: pd.DataFrame) -> Optional[Any]
    def predict_with_ensemble(self, features, market_regime: str = 'undefined') -> Optional[Dict]
    def get_all_required_features(self) -> Set[str]
    def update_model_performance(self, model_name: str, metrics: Dict)
    def setup_auto_retraining(self, config: Dict)
```

**Modelos Suportados:**
- XGBoost (fast)
- LightGBM (balanced)
- Random Forest (stable)
- LSTM (intraday patterns)
- Transformer (attention-based)

### 11. OrderManager (`order_manager_v4.py`)
**Gerencia execuÃ§Ã£o de ordens**

```python
class OrderExecutionManagerV4:
    def __init__(self, connection_manager: ConnectionManagerV4)
    def initialize(self) -> bool
    def create_order(self, signal: Dict, account_info: Dict) -> Optional[SendOrder]
    def send_order(self, order: SendOrder) -> Dict[str, Any]
    def cancel_order(self, order_id: int) -> bool
    def get_order_status(self, order_id: int) -> Optional[Dict]
    def get_open_orders(self) -> List[Dict]
```

### 12. DataPipeline (`data_pipeline.py`)
**Pipeline de processamento de dados**

```python
class DataPipeline:
    def __init__(self, data_structure: TradingDataStructure)
    def process_historical_trades(self, trades: List[Dict]) -> Dict[str, pd.DataFrame]
    def get_aligned_data(self, limit: Optional[int] = None) -> pd.DataFrame
    def update_indicators(self, indicators: pd.DataFrame)
    def clear_old_data(self, keep_days: int = 7)
```

### 13. RealTimeProcessor (`real_time_processor.py`)
**Processa dados em tempo real**

```python
class RealTimeProcessor:
    def __init__(self, data_structure: TradingDataStructure, candle_interval: int = 60)
    def process_trade(self, trade: Dict) -> bool
    def force_close_candle(self)
    def get_current_state(self) -> Dict
    def get_latest_data(self, n_candles: int = 100) -> Dict[str, pd.DataFrame]
```

## ğŸ”„ Fluxo de Dados Completo

### 1. InicializaÃ§Ã£o
```python
# 1. Criar sistema
system = TradingSystem(config)

# 2. Inicializar componentes
system.initialize()

# 3. Iniciar operaÃ§Ã£o
system.start('WDOU25')  # Contrato especÃ­fico
```

### 2. RecepÃ§Ã£o de Dados
```python
# Callback de trade (automÃ¡tico via ProfitDLL)
def on_trade_callback(trade_data):
    # Processa trade
    real_time_processor.process_trade(trade_data)
    
    # Atualiza data structure
    data_structure.update_candles(new_candles)
```

### 3. Ciclo de ML (a cada 60s)
```python
# No ml_worker thread
def _ml_worker():
    while is_running:
        # 1. Calcular features
        features = feature_engine.calculate(data_structure)
        
        # 2. Processar prediÃ§Ã£o
        prediction = ml_coordinator.process_prediction_request(data_structure)
        
        # 3. Enviar para fila de sinais
        if prediction and prediction['can_trade']:
            signal_queue.put(prediction)
```

### 4. GeraÃ§Ã£o de Sinais
```python
# No signal_worker thread
def _signal_worker():
    while is_running:
        prediction = signal_queue.get()
        
        # 1. Gerar sinal
        signal = signal_generator.generate_signal(prediction, data_structure)
        
        # 2. Validar risco
        is_valid, reason = risk_manager.validate_signal(signal, account_balance)
        
        # 3. Executar se vÃ¡lido
        if is_valid:
            order_manager.send_order(signal)
```

## ğŸ“Š Estruturas de Dados Importantes

### Trade (ProfitDLL)
```python
{
    'timestamp': datetime,
    'price': float,
    'volume': int,
    'trade_type': int,  # 2=buy, 3=sell
    'ticker': str
}
```

### Candle (OHLCV)
```python
{
    'open': float,
    'high': float,
    'low': float,
    'close': float,
    'volume': float,
    'timestamp': pd.Timestamp  # index
}
```

### Signal
```python
{
    'timestamp': datetime,
    'action': str,          # 'buy' ou 'sell'
    'entry_price': float,
    'stop_loss': float,
    'take_profit': float,
    'confidence': float,
    'position_size': int,
    'reason': str,
    'metadata': {
        'prediction': dict,
        'atr': float,
        'regime': str
    }
}
```

### Position
```python
{
    'id': str,
    'action': str,
    'entry_price': float,
    'stop_loss': float,
    'take_profit': float,
    'position_size': int,
    'open_time': datetime,
    'status': str  # 'open', 'closed'
}
```

## ğŸ› ï¸ Desenvolvimento e ExtensÃ£o

### Adicionar Nova Feature

1. **Editar `ml_features.py`**:
```python
def calculate_new_feature(self, data: pd.DataFrame) -> pd.Series:
    """Calcula nova feature"""
    # Implementar cÃ¡lculo
    return feature_series
```

2. **Registrar em `FeatureEngine`**:
```python
# Em calculate_ml_features()
features['new_feature'] = ml_features.calculate_new_feature(data)
```

3. **Atualizar `all_required_features.json`**:
```json
{
    "features": [
        "existing_features...",
        "new_feature"
    ]
}
```

### Adicionar Novo Modelo

1. **Treinar modelo** usando `TrainingOrchestrator`
2. **Salvar com metadata**:
```python
# Salvar modelo
joblib.dump(model, 'models/new_model.pkl')

# Salvar features
with open('models/new_model_features.json', 'w') as f:
    json.dump({'features': feature_list}, f)
```

3. **ModelManager carregarÃ¡ automaticamente**

### Implementar Nova EstratÃ©gia

1. **Criar classe de estratÃ©gia**:
```python
class NewStrategy:
    def evaluate(self, prediction: Dict, market_data) -> Dict:
        # LÃ³gica da estratÃ©gia
        return signal
```

2. **Integrar em `StrategyEngine`**:
```python
self.strategies['new_strategy'] = NewStrategy(config)
```

### Adicionar Novo Indicador

1. **Editar `technical_indicators.py`**:
```python
@staticmethod
def calculate_new_indicator(df: pd.DataFrame, period: int = 14) -> pd.Series:
    """Calcula novo indicador"""
    # ImplementaÃ§Ã£o
    return indicator_series
```

2. **Registrar em `_calculate_all_indicators()`**:
```python
indicators['new_indicator'] = self.calculate_new_indicator(candles)
```

## ğŸ”§ ConfiguraÃ§Ã£o e Ambiente

### VariÃ¡veis de Ambiente
```bash
# .env file
TRADING_ENV=development  # ou 'production'
LOG_LEVEL=INFO
USE_GPU=false
```

### Estrutura de DiretÃ³rios
```
QuantumTrader_ML/
â”œâ”€â”€ src/                    # CÃ³digo fonte
â”‚   â”œâ”€â”€ training/          # Sistema de treinamento
â”‚   â”œâ”€â”€ features/          # DocumentaÃ§Ã£o de features
â”‚   â””â”€â”€ tests/             # Testes unitÃ¡rios
â”œâ”€â”€ models/                # Modelos treinados (.pkl)
â”œâ”€â”€ data/                  # Dados histÃ³ricos
â”œâ”€â”€ logs/                  # Logs do sistema
â””â”€â”€ config/                # ConfiguraÃ§Ãµes
```

### Logging
```python
# Configurar logging
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    handlers=[
        logging.FileHandler('logs/trading_system.log'),
        logging.StreamHandler()
    ]
)
```

## ğŸš¨ Pontos CrÃ­ticos de AtenÃ§Ã£o

### 1. ValidaÃ§Ã£o de Dados de ProduÃ§Ã£o
```python
# SEMPRE validar dados antes de usar
self._validate_production_data(data, source, data_type)
```

### 2. Threading e SincronizaÃ§Ã£o
```python
# Usar Event para sincronizaÃ§Ã£o
self.historical_data_ready = threading.Event()

# Aguardar dados
if not self.historical_data_ready.wait(timeout=180):
    raise TimeoutError("Dados nÃ£o carregados")
```

### 3. Contratos WDO
```python
# Sistema determina contrato automaticamente
contract = self._get_current_contract(datetime.now())
# Ex: Em agosto/2025 â†’ WDOU25
```

### 4. GestÃ£o de MemÃ³ria
```python
# Limpar dados antigos periodicamente
data_pipeline.clear_old_data(keep_days=7)

# Limitar tamanho de DataFrames
MAX_CANDLES = 10000
```

### 5. Tratamento de Erros
```python
try:
    # OperaÃ§Ã£o crÃ­tica
    result = critical_operation()
except SpecificError as e:
    logger.error(f"Erro especÃ­fico: {e}")
    # AÃ§Ã£o de recuperaÃ§Ã£o
except Exception as e:
    logger.error(f"Erro nÃ£o esperado: {e}", exc_info=True)
    # Falhar de forma segura
```

## ğŸ“ Checklist para Novos Desenvolvedores

- [ ] Ler `CLAUDE.md` para entender filosofia do sistema
- [ ] Estudar `MAPA_FLUXO_DADOS_SISTEMA_01082025.md`
- [ ] Configurar ambiente de desenvolvimento
- [ ] Executar testes unitÃ¡rios: `pytest`
- [ ] Rodar sistema em modo simulaÃ§Ã£o primeiro
- [ ] Entender regime detection antes de ML
- [ ] Sempre validar dados de produÃ§Ã£o
- [ ] Usar logging extensivamente
- [ ] Seguir padrÃµes de cÃ³digo existentes
- [ ] Documentar mudanÃ§as significativas

## ğŸ”— ReferÃªncias Importantes

- **DocumentaÃ§Ã£o ProfitDLL**: `profitdll-order-guide.md`
- **ML Strategy**: `ml-prediction-strategy-doc.md`
- **Sistema de Treinamento**: `SISTEMA_TREINAMENTO_INTEGRADO.md`
- **Developer Guide**: `DEVELOPER_GUIDE.md`

## ğŸ†• AtualizaÃ§Ãµes Recentes (Agosto 2025)

### Sistema de Coleta de Book de Ofertas
**Status**: âœ… Implementado e otimizado (04/08/2025)

#### Componentes Principais:

1. **BookCollectorFinalSolution** (`book_collector_final_solution.py`)
   - VersÃ£o mais robusta e estÃ¡vel
   - Suporta mÃºltiplos tickers simultaneamente
   - NÃ£o trava durante coleta
   - Salva dados em JSON e Parquet
   - Re-registra callbacks apÃ³s login (crÃ­tico!)

2. **Callbacks Implementados**:
   ```python
   # TinyBook - Dados agregados de mercado
   @WINFUNCTYPE(None, c_wchar_p, c_wchar_p, c_double, c_int, c_int)
   def tinyBookCallback(ticker, bolsa, price, qtd, side)
   
   # OfferBook - Livro de ofertas detalhado
   @WINFUNCTYPE(None, c_wchar_p, c_wchar_p, c_int, c_int, c_int, c_int, c_int, c_longlong, c_double, ...)
   def offerBookCallback(ticker, bolsa, nAction, nPosition, Side, nQtd, ...)
   
   # Trade - NegÃ³cios realizados
   @WINFUNCTYPE(None, c_wchar_p, c_double, c_int, c_int, c_int)
   def tradeCallback(ticker, price, qty, buyer, seller)
   ```

3. **Estrutura de Dados Coletados**:
   ```python
   {
       'type': 'tiny_book/offer_book/trade',
       'ticker': str,
       'side': 'bid/ask',
       'price': float,
       'quantity': int,
       'timestamp': datetime.isoformat()
   }
   ```

4. **Scripts de Coleta**:
   - `book_collector_final_solution.py` - VersÃ£o principal para produÃ§Ã£o
   - `book_collector_minimal_working.py` - VersÃ£o simplificada para debug
   - `scripts/book_collector.py` - Interface original (mantida para compatibilidade)

**Importante**: 
- Executar apenas durante horÃ¡rio de pregÃ£o (seg-sex, 9h-18h)
- ProfitDLL nÃ£o fornece book histÃ³rico, apenas real-time
- Callbacks devem ser re-registrados APÃ“S login com SetOfferBookCallbackV2()

### Sistema de Treinamento Dual (CSV/Tick + Book)
**Status**: âœ… Implementado com integraÃ§Ã£o HMARL

O sistema suporta dois modos de treinamento complementares para uma estratÃ©gia completa:

#### 1. Treinamento com Dados CSV (Tick/OHLCV)
**Objetivo**: Capturar tendÃªncias de mÃ©dio/longo prazo e padrÃµes tÃ©cnicos

```python
from src.training.training_orchestrator import TrainingOrchestrator

# ConfiguraÃ§Ã£o para dados CSV
config = {
    'data_path': 'data/csv/',  # Arquivos CSV com OHLCV
    'model_save_path': 'models/tick_models/',
    'features': {
        'technical': True,      # RSI, MACD, Bollinger, etc
        'regime': True,         # DetecÃ§Ã£o de regime
        'momentum': True,       # Features de momentum
        'volatility': True      # Features de volatilidade
    }
}

# Treinar modelos
orchestrator = TrainingOrchestrator(config)
results = orchestrator.train_from_csv(
    csv_file='data/csv/WDOU25_2024_2025.csv',
    lookback_days=365,  # 1 ano de dados
    target='direction'   # Prever direÃ§Ã£o do movimento
)
```

**Features CSV/Tick** (~100 features):
- Indicadores tÃ©cnicos clÃ¡ssicos
- PadrÃµes de candlestick
- AnÃ¡lise de volume
- DetecÃ§Ã£o de suporte/resistÃªncia
- Regime de mercado (trend/range)

#### 2. Treinamento com Book de Ofertas
**Objetivo**: Capturar microestrutura e fluxo de ordens para timing preciso

```python
from src.training.book_training_pipeline import BookTrainingPipeline

# ConfiguraÃ§Ã£o para dados de book
config = {
    'data_path': 'data/realtime/book/',
    'model_save_path': 'models/book_models/',
    'features': {
        'order_flow': True,     # OFI, delta, absorÃ§Ã£o
        'liquidity': True,      # Profundidade, spread
        'microstructure': True, # Kyle's Lambda, PIN
        'patterns': True        # Iceberg, sweep, spoofing
    }
}

# Treinar modelos de book
pipeline = BookTrainingPipeline(config)
results = pipeline.train_book_models(
    start_date='2025-07-01',
    end_date='2025-08-01',
    targets=['spread_change', 'price_move_1min', 'order_imbalance']
)
```

**Features Book** (~80 features):
- Order Flow Imbalance (OFI)
- Volume delta por nÃ­vel
- Microestrutura de preÃ§os
- PadrÃµes de execuÃ§Ã£o
- MÃ©tricas de liquidez

#### 3. Sistema Dual Integrado
**Combina ambos para decisÃµes completas**

```python
from src.training.dual_training_system import DualTrainingSystem

# Sistema completo
dual_system = DualTrainingSystem({
    'tick_config': {...},    # Config para CSV/tick
    'book_config': {...},    # Config para book
    'ensemble_method': 'weighted',  # Como combinar
    'hmarl_integration': True       # Usar HMARL
})

# Treinar ambos os modelos
results = dual_system.train_complete_system(
    csv_files=['WDOU25_2024.csv', 'WDOU25_2025.csv'],
    book_data_path='data/realtime/book/',
    validation_split=0.2
)

# Resultados incluem:
# - Modelos de tendÃªncia (tick)
# - Modelos de microestrutura (book)
# - Pesos de ensemble
# - MÃ©tricas por regime
```

#### 4. PreparaÃ§Ã£o de Dados

**Para CSV/Tick**:
```bash
# Preparar CSV para ML
python prepare_csv_for_ml.py --input data/raw/WDOU25.csv --output data/csv/

# Estrutura esperada do CSV:
# timestamp, open, high, low, close, volume
```

**Para Book**:
```bash
# Coletar book durante pregÃ£o
python book_collector_final_solution.py

# Processar book coletado
python scripts/process_book_data.py --date 2025-08-05
```

#### 5. ValidaÃ§Ã£o PrÃ©-Treinamento

```bash
# Validar dados antes de treinar
python scripts/pre_training_validation.py

# Checa:
# âœ“ Dados CSV disponÃ­veis e vÃ¡lidos
# âœ“ Dados de book coletados
# âœ“ Features calculÃ¡veis
# âœ“ Sem gaps temporais
# âœ“ Qualidade dos dados
```

### IntegraÃ§Ã£o HMARL (Hierarchical Multi-Agent RL)
**Status**: âœ… Sistema completo implementado

O HMARL integra mÃºltiplos agentes especializados para anÃ¡lise de microestrutura e fluxo de ordens, complementando o sistema ML tradicional.

#### Arquitetura HMARL

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Sistema Principal                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ ML Models   â”‚  â”‚ Book Collectorâ”‚  â”‚ ProfitDLL  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                  â”‚                 â”‚       â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                           â”‚                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚                    â”‚ HMARL Bridgeâ”‚                  â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â–¼                  â”‚
        â”‚         Flow Coordinator            â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
        â”‚  â”‚Agent 1 â”‚  â”‚Agent 2 â”‚  â”‚Agent N â”‚â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
        â”‚         â”‚        â”‚         â”‚        â”‚
        â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
        â”‚                  â–¼                  â”‚
        â”‚            Consensus                â”‚
        â”‚             Engine                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 1. Componentes Principais

**HMARLMLBridge** (`src/infrastructure/hmarl_ml_integration.py`)
```python
class HMARLMLBridge:
    def __init__(self, ml_system, config):
        self.flow_analyzer = OrderFlowAnalyzer()
        self.footprint_tracker = FootprintTracker()
        self.agents = self._initialize_agents()
        
    def intercept_book_callback(self, book_data):
        # Processa book e distribui para agentes
        flow_features = self.flow_analyzer.analyze(book_data)
        footprint = self.footprint_tracker.update(book_data)
        
        # Broadcast para agentes via ZMQ
        self.broadcast_to_agents({
            'book': book_data,
            'flow': flow_features,
            'footprint': footprint
        })
```

**FlowAwareCoordinator** (`src/coordination/flow_aware_coordinator.py`)
```python
class FlowAwareCoordinator:
    def __init__(self, valkey_client):
        self.agents = {}
        self.consensus_engine = ConsensusEngine()
        self.signal_quality_scorer = SignalQualityScorer()
        
    def coordinate_decision(self, ml_signal, agent_signals):
        # Combina ML tradicional com insights dos agentes
        consensus = self.consensus_engine.evaluate({
            'ml_signal': ml_signal,
            'agent_signals': agent_signals
        })
        
        # Score de qualidade final
        quality_score = self.signal_quality_scorer.score(
            consensus, 
            market_context=self.get_market_context()
        )
        
        return {
            'action': consensus['action'],
            'confidence': consensus['confidence'] * quality_score,
            'agent_consensus': consensus['agreement_level']
        }
```

#### 2. Agentes Especializados

**OrderFlowSpecialist** (`src/agents/order_flow_specialist.py`)
- Analisa Order Flow Imbalance (OFI)
- Detecta momentum de compra/venda
- Identifica absorÃ§Ã£o em nÃ­veis chave

**LiquiditySpecialist** (`src/agents/liquidity_specialist.py`)
- Monitora profundidade do book
- Calcula mÃ©tricas de liquidez
- Detecta mudanÃ§as sÃºbitas de liquidez

**TapeReadingAgent** (`src/agents/tape_reading_agent.py`)
- Analisa velocidade de execuÃ§Ã£o
- Identifica padrÃµes de agressÃ£o
- Detecta icebergs e hidden orders

**FootprintAgent** (`src/agents/footprint_agent.py`)
- Rastreia volume por preÃ§o
- Identifica nÃ­veis de absorÃ§Ã£o
- Mapeia zonas de interesse institucional

#### 3. Infraestrutura de ComunicaÃ§Ã£o

**Portas ZMQ**:
```python
PORTS = {
    'tick_data': 5555,      # Dados de trades
    'order_book': 5556,     # Book completo
    'flow_analysis': 5557,  # AnÃ¡lise de fluxo
    'footprint': 5558,      # Dados de footprint
    'liquidity': 5559,      # MÃ©tricas de liquidez
    'tape_reading': 5560,   # Tape reading
    'consensus': 5561       # DecisÃµes consensuais
}
```

**Valkey/Redis Storage**:
```python
# Estrutura de streams
STREAMS = {
    'book:WDOU25': TTL(300),      # 5min de book
    'flow:WDOU25': TTL(600),      # 10min de flow
    'footprint:WDOU25': TTL(1800), # 30min footprint
    'signals:*': TTL(3600)         # 1h de sinais
}

# Time-travel queries
valkey.xrange('book:WDOU25', min='-', max='+', count=1000)
```

#### 4. IntegraÃ§Ã£o com Sistema Principal

```python
# Exemplo de uso completo
from examples.hmarl_integrated_trading import HMARLIntegratedTrading

# ConfiguraÃ§Ã£o
config = {
    'ml_models_path': 'models/',
    'hmarl': {
        'agents': ['order_flow', 'liquidity', 'tape_reading', 'footprint'],
        'consensus_threshold': 0.7,
        'valkey_host': 'localhost',
        'valkey_port': 6379
    },
    'trading': {
        'symbol': 'WDOU25',
        'risk_per_trade': 0.02
    }
}

# Inicializar sistema integrado
system = HMARLIntegratedTrading(config)
system.initialize()

# Sistema agora usa:
# 1. Modelos ML para tendÃªncia (CSV/tick data)
# 2. Modelos de book para microestrutura
# 3. Agentes HMARL para consenso e validaÃ§Ã£o
# 4. Coordenador para decisÃ£o final

system.start_trading()
```

#### 5. Fluxo de DecisÃ£o HMARL

1. **Coleta de Dados**:
   - Book collector alimenta HMARL Bridge
   - Bridge processa e distribui para agentes

2. **AnÃ¡lise Paralela**:
   - Cada agente analisa sua especialidade
   - Resultados enviados ao coordenador

3. **Consenso**:
   - Coordenador combina sinais ML + agentes
   - Engine calcula nÃ­vel de concordÃ¢ncia
   - Quality scorer valida contexto

4. **ExecuÃ§Ã£o**:
   - Sinal final com alta confianÃ§a executado
   - Feedback registrado para aprendizado

#### 6. Monitoramento HMARL

```bash
# Dashboard de agentes
python scripts/hmarl_dashboard.py

# MÃ©tricas por agente
python scripts/agent_performance.py --agent order_flow

# AnÃ¡lise de consenso
python scripts/consensus_analysis.py --date 2025-08-04
```

### Scripts de ValidaÃ§Ã£o PrÃ©-Treinamento
**Status**: âœ… Implementados

1. **check_historical_data.py** - Valida dados tick histÃ³ricos
2. **check_book_data.py** - Valida dados de book coletados
3. **setup_directories.py** - Cria estrutura necessÃ¡ria
4. **pre_training_validation.py** - ValidaÃ§Ã£o completa do sistema

### Comandos e Exemplos PrÃ¡ticos

#### 1. Coleta de Dados

**Coletar Book de Ofertas (Durante PregÃ£o)**:
```bash
# Coletor principal - mais estÃ¡vel
python book_collector_final_solution.py

# Coletor com interface amigÃ¡vel
python scripts/book_collector.py --symbol WDOU25 --duration 3600

# Coletor mÃ­nimo para debug
python book_collector_minimal_working.py
```

**Verificar Dados Coletados**:
```bash
# Verificar book coletado
python scripts/check_book_data.py --date 2025-08-05

# Verificar dados histÃ³ricos CSV
python scripts/check_historical_data.py --symbol WDOU25
```

#### 2. PreparaÃ§Ã£o de Dados

**Preparar CSV para ML**:
```bash
# Converter CSV bruto para formato ML
python prepare_csv_for_ml.py \
    --input data/raw/WDOU25_2024.csv \
    --output data/csv/WDOU25_2024_ml.csv \
    --add-features true

# Validar qualidade dos dados
python scripts/validate_data_quality.py --file data/csv/WDOU25_2024_ml.csv
```

**Processar Book Coletado**:
```bash
# Agregar book em candles de 1min
python scripts/process_book_data.py \
    --date 2025-08-05 \
    --output data/processed/book_features_20250805.parquet

# Gerar features de microestrutura
python scripts/generate_book_features.py \
    --input data/realtime/book/20250805/ \
    --output data/features/book/
```

#### 3. Treinamento de Modelos

**Treinar Modelo com CSV (TendÃªncias)**:
```python
from src.training.training_orchestrator import TrainingOrchestrator

# ConfiguraÃ§Ã£o bÃ¡sica
config = {
    'data_path': 'data/csv/',
    'model_save_path': 'models/tick/',
    'validation_split': 0.2,
    'walk_forward_windows': 5
}

# Treinar
orchestrator = TrainingOrchestrator(config)
results = orchestrator.train_from_csv(
    csv_file='data/csv/WDOU25_2024_ml.csv',
    lookback_days=365,
    models=['xgboost', 'lightgbm', 'random_forest']
)

print(f"Melhor modelo: {results['best_model']}")
print(f"Accuracy: {results['metrics']['accuracy']:.2%}")
```

**Treinar Modelo com Book (Microestrutura)**:
```python
from src.training.book_training_pipeline import BookTrainingPipeline

# ConfiguraÃ§Ã£o para book
config = {
    'data_path': 'data/realtime/book/',
    'model_save_path': 'models/book/',
    'min_samples': 10000,
    'imbalance_threshold': 0.7
}

# Treinar mÃºltiplos targets
pipeline = BookTrainingPipeline(config)
results = pipeline.train_book_models(
    start_date='2025-07-01',
    end_date='2025-08-01',
    targets=['spread_change', 'price_move_1min', 'order_imbalance']
)

# Resultados por target
for target, metrics in results.items():
    print(f"\n{target}: RÂ² = {metrics['r2']:.3f}")
```

**Sistema Dual Completo**:
```bash
# Script automatizado
python examples/train_dual_models.py \
    --symbol WDOU25 \
    --csv-lookback 365 \
    --book-lookback 30 \
    --output models/dual/

# Ou via cÃ³digo
from src.training.dual_training_system import DualTrainingSystem

system = DualTrainingSystem({
    'tick_config': {
        'lookback_days': 365,
        'features': ['technical', 'regime', 'momentum']
    },
    'book_config': {
        'lookback_days': 30,
        'features': ['order_flow', 'liquidity', 'microstructure']
    },
    'ensemble_method': 'stacking',
    'hmarl_integration': True
})

results = system.train_complete_system(
    csv_files=['data/csv/WDOU25_2024.csv', 'data/csv/WDOU25_2025.csv'],
    book_data_path='data/realtime/book/'
)
```

#### 4. Trading com Sistema Completo

**Trading BÃ¡sico (Sem HMARL)**:
```python
from src.trading_system import TradingSystem

config = {
    'dll_path': './ProfitDLL64.dll',
    'username': 'seu_usuario',
    'password': 'sua_senha',
    'models_dir': 'models/dual/',
    'use_book_features': True,
    'ml_interval': 60
}

system = TradingSystem(config)
system.initialize()
system.start('WDOU25')
```

**Trading com HMARL**:
```python
from examples.hmarl_integrated_trading import HMARLIntegratedTrading

config = {
    'base_config': {...},  # Config do sistema base
    'hmarl': {
        'agents': ['order_flow', 'liquidity', 'tape_reading'],
        'consensus_threshold': 0.7,
        'valkey_host': 'localhost'
    }
}

system = HMARLIntegratedTrading(config)
system.initialize()
system.start_trading('WDOU25')
```

#### 5. Backtesting

**Backtest com Dados CSV**:
```bash
python src/ml_backtester.py \
    --model models/tick/xgboost_20250804.pkl \
    --data data/csv/WDOU25_test.csv \
    --start 2025-01-01 \
    --end 2025-07-31
```

**Backtest com Book (Replay)**:
```python
from src.backtesting.book_replay_engine import BookReplayEngine

engine = BookReplayEngine({
    'book_data': 'data/realtime/book/',
    'tick_model': 'models/tick/best_model.pkl',
    'book_model': 'models/book/microstructure.pkl',
    'initial_capital': 100000
})

results = engine.run_replay(
    start_date='2025-07-01',
    end_date='2025-07-31',
    use_hmarl=True
)

print(f"Sharpe Ratio: {results['sharpe']:.2f}")
print(f"Max Drawdown: {results['max_drawdown']:.1%}")
```

#### 6. Monitoramento e Debug

**Monitor em Tempo Real**:
```bash
# Dashboard do sistema
python scripts/trading_dashboard.py

# Monitor de agentes HMARL
python scripts/hmarl_monitor.py --agents all

# Log viewer
tail -f logs/trading_system.log | grep -E "(SIGNAL|TRADE|ERROR)"
```

**Debug de Features**:
```python
# Verificar features calculadas
from src.features.feature_debugger import FeatureDebugger

debugger = FeatureDebugger()
debugger.check_features('data/features/latest.parquet')
debugger.plot_correlations()
debugger.find_missing_values()
```

#### 7. ManutenÃ§Ã£o

**Limpeza de Dados**:
```bash
# Limpar dados antigos (manter Ãºltimos 30 dias)
python scripts/cleanup_old_data.py --keep-days 30

# Compactar book histÃ³rico
python scripts/compress_book_data.py --before 2025-07-01
```

**AtualizaÃ§Ã£o de Modelos**:
```bash
# Re-treinar com dados recentes
python scripts/retrain_models.py --incremental true

# Validar modelos antes de produÃ§Ã£o
python scripts/validate_models.py --path models/new/
```

### PrÃ³ximos Passos Pendentes:

1. **ValidaÃ§Ã£o Cruzada Temporal AvanÃ§ada**
   - Walk-forward analysis mais robusta
   - Purged cross-validation para evitar data leakage
   - MÃ©tricas especÃ­ficas por regime

2. **Sistema de Backtesting com Book**
   - Replay de book histÃ³rico
   - SimulaÃ§Ã£o de agentes HMARL
   - AnÃ¡lise de impacto de mercado

3. **OtimizaÃ§Ã£o de ProduÃ§Ã£o**
   - Auto-tuning de hiperparÃ¢metros
   - Monitoramento de drift
   - A/B testing de estratÃ©gias

### DocumentaÃ§Ã£o Criada:

- `PRE_TRAINING_CHECKLIST.md` - Checklist completo antes do treinamento
- `DUAL_TRAINING_HMARL_INTEGRATION.md` - Guia da integraÃ§Ã£o
- `docs/HMARL_*.md` - DocumentaÃ§Ã£o completa HMARL

### Arquivos Importantes Modificados:

1. **connection_manager_v4.py** - Adicionados callbacks de book
2. **dual_training_system.py** - Sistema dual com HMARL
3. **Novos arquivos em src/infrastructure/** - Infraestrutura HMARL
4. **Novos arquivos em src/agents/** - Agentes especializados
5. **Novos arquivos em src/coordination/** - Coordenadores

### Problemas Conhecidos e SoluÃ§Ãµes

#### 1. Book Collector Travando
**Problema**: Sistema trava apÃ³s subscrever tickers
**SoluÃ§Ã£o**: 
- Use `book_collector_final_solution.py` (mais estÃ¡vel)
- Execute apenas durante pregÃ£o (seg-sex, 9h-18h)
- Re-registre callbacks apÃ³s login com SetOfferBookCallbackV2()

#### 2. Dados Corrompidos
**Problema**: Ticker aparece como unicode invÃ¡lido ('\ua9d0\u5eec\u029b')
**SoluÃ§Ã£o**:
- Problema de marshalling do ctypes
- Use versÃ£o final que valida dados antes de salvar
- Filtre dados com preÃ§os <= 0 ou > 1000000

#### 3. Sem Dados no Book
**Problema**: Callbacks nÃ£o sÃ£o disparados
**SoluÃ§Ã£o**:
- Verifique se Ã© horÃ¡rio de pregÃ£o
- Tente mÃºltiplos tickers (WDOU25, PETR4, VALE3)
- Use RequestMarketData() como fallback

#### 4. ModuleNotFoundError
**Problema**: MÃ³dulos nÃ£o encontrados ao importar
**SoluÃ§Ã£o**:
```bash
# Adicionar ao PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:/caminho/para/QuantumTrader_ML"

# Ou no cÃ³digo
import sys
sys.path.append('/caminho/para/QuantumTrader_ML')
```

---

*Ãšltima atualizaÃ§Ã£o: 04/08/2025*
*VersÃ£o do Sistema: 2.1.1 (com HMARL e Book Collector otimizado)*